#!/usr/bin/env python3

import os
libpath = os.path.normpath(                                                    \
            os.path.join(                                                      \
                os.path.dirname(os.path.abspath(os.path.realpath(__file__))),  \
                '..')                                                          \
            )
import sys
sys.path.append(libpath)

import distutils.util
import argparse
import csv
import numpy

import matplotlib.pyplot as plt
from matplotlib.animation import FuncAnimation

import tensorflow       as     tf
from   tensorflow.data  import Dataset
from   tensorflow.keras import layers, Model, Sequential, optimizers, losses, \
                               metrics, callbacks, initializers
from tensorflow.keras.layers.experimental import preprocessing

import tensorflow_datasets as tfds

from   gmcdp._version     import __version__
from   gmcdp.GausNoiseOn  import GausNoiseOn

### class definitions ----------------------------------------------------------

# generative adversarial network
class GAN(Model):

  def __init__(self, disc, gen, latent_dim):
    super(GAN, self).__init__()
    self.discriminator = disc
    self.generator     = gen
    self.latent_dim    = latent_dim
    return

  def compile(self, optD, optG, loss_fn):
    super(GAN, self).compile()
    self.optD    = optD
    self.optG    = optG
    self.loss_fn = loss_fn
    # gradient penalty weight
    self.gp_weight = 10.0
    # label smoothing values
    self.real_min = 0.99
    self.real_max = 1.01
    self.fake_min = -1.01
    self.fake_max = -0.99
    return

  def grad_penalty(self, data):
    with tf.GradientTape() as gp_tape:
      gp_tape.watch(data)
      pred = self.discriminator(data, training=True)
    gp_grds = gp_tape.gradient(pred, [data])[0]
    norm    = tf.sqrt(tf.reduce_sum(tf.square(gp_grds), axis=[1,2]))
    gp      = tf.reduce_mean((norm-1.0)**2)
    return gp

  def train_step(self, real_data):
    if isinstance(real_data, tuple):
      real_data = real_data[0]
    # batch size
    bs = tf.shape(real_data)[0]

    # train discriminator on real data
    with tf.GradientTape() as tape:
      labels  = -tf.ones((bs,1))
      preds   = self.discriminator(real_data, training=True)
      cost    = self.loss_fn(labels, preds)
      gp      = self.grad_penalty(real_data)
      d_lossR = cost + gp * self.gp_weight
      grads   = tape.gradient(d_lossR, self.discriminator.trainable_weights)
      self.optD.apply_gradients(zip(grads,
                                    self.discriminator.trainable_weights))

    # train discriminator on fake data
    with tf.GradientTape() as tape:
      # generate fake data
      z = tf.random.normal(shape=(bs, self.latent_dim))
      fake_data = self.generator(z, training=True)
      # train
      labels  = tf.ones((bs,1))
      preds   = self.discriminator(fake_data, training=True)
      cost    = self.loss_fn(labels, preds)
      gp      = self.grad_penalty(fake_data)
      d_lossG = cost + gp * self.gp_weight
      grads   = tape.gradient(d_lossG, self.discriminator.trainable_weights)
      self.optD.apply_gradients(zip(grads,
                                    self.discriminator.trainable_weights))

    # train generator
    with tf.GradientTape() as tape:
      # create misleading labels for generator
      misleading_labels = -tf.ones((bs,1))
      z = tf.random.normal(shape=(bs, self.latent_dim))
      # train
      fake_preds = self.discriminator(self.generator(z, training=True))
      g_loss     = self.loss_fn(misleading_labels, fake_preds)
      grads      = tape.gradient(g_loss, self.generator.trainable_weights)
      self.optG.apply_gradients(zip(grads, self.generator.trainable_weights))

    return {'d_loss_real':d_lossR, 'd_loss_fake':d_lossG, 'g_loss':g_loss}


  def summary(self, line_length=None, positions=None, print_fn=None):
    self.discriminator.summary(line_length, positions, print_fn)
    self.generator.summary(line_length, positions, print_fn)
    return

### function definitions -------------------------------------------------------

### build discriminator model
def build_discriminator(data_dim):
  fltrs      = 256
  filtersize = 5
  init       = initializers.RandomNormal(mean=0.0, stddev=0.02)

  model = Sequential(name='discriminator')
  model.add(layers.Conv1D(fltrs//2, filtersize, padding='same',
                                                kernel_initializer=init,
                                                input_shape=(data_dim,1,)))
  model.add(layers.LeakyReLU())

  model.add(layers.Conv1D(fltrs, filtersize, padding='same',
                                             kernel_initializer=init))
  model.add(layers.LeakyReLU())
  model.add(layers.LayerNormalization())

  model.add(layers.Conv1D(fltrs//2, filtersize, padding='same',
                                                kernel_initializer=init))
  model.add(layers.LeakyReLU())
  model.add(layers.LayerNormalization())

  model.add(layers.Flatten())
  model.add(layers.Dense(fltrs//2, kernel_initializer=init))
  model.add(layers.LeakyReLU())
  model.add(layers.Dense(1, kernel_initializer=init))
  return model


### build a generator block
def gen_block(inlayer, n_neurons, block_id, filtersize, use_bias, init):
  conv = layers.Conv1DTranspose(n_neurons, filtersize,
                                padding='same',
                                use_bias=use_bias,
                                kernel_initializer=init,
                                name='convt_'+str(block_id))(inlayer)
  bn = layers.BatchNormalization(name='bn_'+str(block_id))(conv)
  mu = layers.LeakyReLU(name='mu_'+str(block_id))(bn)
  mp = layers.MaxPool1D(filtersize, 1,
                        padding='same',
                        name='pool_'+str(block_id))(mu)
  gn = GausNoiseOn(stddev=1.0, name='noise_'+str(block_id))(mp)
  Lout = layers.Add(name='out_'+str(block_id))([mu,gn])
  return Lout

### build generator model
def build_generator(data_dim, blocks, nrons):
  filtersize = 5
  use_bias   = False
  init       = initializers.RandomNormal(mean=0.0, stddev=0.02)

  #Lin  = layers.Input(shape=(latent_dim), name='gen_in')
  #Ld   = layers.Dense(data_dim*nrons, use_bias=use_bias,
  #                                    kernel_initializer=init,
  #                                    name='dense_in')(Lin)
  #bn   = layers.BatchNormalization(name='bn_in')(Ld)
  #af   = layers.LeakyReLU(name='relu_in')(bn)
  #tout = layers.Reshape((data_dim, nrons), name='reshape_in')(af)

  Lin  = layers.Input(shape=(data_dim), name='gen_in')
  rshp = layers.Reshape((data_dim, 1), name='reshape_in')(Lin)
  lstm = layers.Bidirectional(layers.LSTM(nrons, kernel_initializer=init,
                               return_sequences=True), name='lstm')(rshp)
  tout = layers.BatchNormalization(name='bn_in')(lstm)

  for i in range(blocks):
    if i == 0:
      tout = gen_block(tout, nrons, i, filtersize, use_bias, init)
    else:
      tout = gen_block(tout, nrons//2, i, filtersize, use_bias, init)

  Lout = layers.Conv1DTranspose(1, filtersize,
                                padding='same',
                                use_bias=use_bias,
                                kernel_initializer=init,
                                activation='relu',
                                name='gen_out')(tout)

  return Model(inputs=Lin, outputs=Lout, name='generator')


### store samples from generator in points_list
def store_samples(epoch, generator, z, points_list):
  every = 10
  if epoch %10 == 0:
    generated_data = generator(z).numpy()
    points_list.append(generated_data)
    return

### build Dataset from data file
def get_real_data(filename, buffersize, batchsize):
  indata = []
  with open(filename, 'r') as handle:
    reader = csv.reader(handle)
    for row in reader:
      indata.append([[float(x)] for x in row])
  data = Dataset.from_tensor_slices(indata)
  data = data.map(lambda x: -tf.math.log(x))
  data = data.shuffle(buffersize).batch(batchsize)
  return data

### wasserstein loss function
@tf.function
def wasserstein_loss(tlabs, plabs):
  return tf.reduce_mean(tlabs * plabs)

### main -----------------------------------------------------------------------
if __name__ == '__main__':
  parser = argparse.ArgumentParser(
                description='calculates profiles from a pssm txt file',
                formatter_class=argparse.ArgumentDefaultsHelpFormatter)
  parser.add_argument('--version', action='version', version=__version__)

  # data source
  parser.add_argument('-f', '--file', dest='file', help='data file',
                      metavar='DATA.csv', required=True)
  parser.add_argument('--data_dim', dest='data_dim', type=int,
                      help='size of data vector', metavar='N')

  # data pre-processing
  parser.add_argument('--buffer_size', dest='buffer_size', type=int,
                      help='data shuffling buffer', metavar='N')
  parser.add_argument('--batch_size', dest='batch_size', type=int,
                      help='training batch size', metavar='N')

  # neural network architecture
  parser.add_argument('--gen_blocks', dest='gen_blocks', type=int,
                      help='number of generator blocks', metavar='N')
  parser.add_argument('--filters', dest='n_filters', type=int,
                      help='number of neurons or filters', metavar='N')

  # training regime
  parser.add_argument('--epochs', dest='epochs', type=int,
                      help='number of training epochs', metavar='N')

  parser.set_defaults(file=None,
                      data_dim=256,
                      buffer_size=10000,
                      batch_size=64,
                      gen_blocks=3,
                      n_filters=128,
                      epochs=1000)

  args = parser.parse_args()

  # get 'real' data
  train_data = get_real_data(args.file,
                             args.buffer_size,
                             args.batch_size)
  print(train_data.element_spec)

  # build discriminator and generator models
  discriminator = build_discriminator(args.data_dim)
  generator     = build_generator(args.data_dim,
                                  args.gen_blocks,
                                  args.n_filters)

  # build GAN
  gan = GAN(discriminator, generator, args.data_dim)
  gan.compile(optimizers.Adam(learning_rate=2.0e-4, beta_1=0.5),
              optimizers.Adam(learning_rate=2.0e-4, beta_1=0.5),
              wasserstein_loss)

  gan.summary()

  # set up generator logging
  n_samples = 10
  real_points_list = [ x.ravel() for x in tfds.as_numpy(train_data.take(1)\
                                                        .unbatch()\
                                                        .take(n_samples)) ]
  sample_zs = tf.random.normal(shape=(n_samples, args.data_dim))

  gen_points_list = []
  cbk = callbacks.LambdaCallback(on_epoch_end=lambda epoch,logs: \
                                              store_samples(epoch,
                                                            gan.generator,
                                                            sample_zs,
                                                            gen_points_list))

  # fit generative adverserial network
  gan.fit(train_data, epochs=args.epochs, callbacks=[cbk], verbose=True)

  # plot results
  x = numpy.linspace(1,args.data_dim,num=args.data_dim)

  fig,axs = plt.subplots(nrows=2, ncols=n_samples, sharex=True, sharey=True)
  axs[0,0].set_ylabel('real data')
  axs[1,0].set_ylabel('sim data')
  dyn_data = []
  for i in range(n_samples):
    ax = axs[0,i]
    y  = real_points_list[i]
    ax.plot(x,y, 'bo', markersize=2)
    dd, = axs[1,i].plot([],[], 'ro', markersize=2)
    dyn_data.append(dd)

  def update(data_idx):
    data = gen_points_list[data_idx]
    for i in range(n_samples):
      y  = data[i,:,:].ravel()
      dyn_data[i].set_data(x,y)
      fig.suptitle('generation {}'.format(data_idx))
    return dyn_data,

  anim = FuncAnimation(fig, update,
                       frames=numpy.arange(0,len(gen_points_list)),
                       interval=200)
  plt.show()

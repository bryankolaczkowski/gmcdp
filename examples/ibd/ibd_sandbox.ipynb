{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ibd_sandbox.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNac1lVMtJgBWKMmz5YQXsZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bryankolaczkowski/gmcdp/blob/main/examples/ibd/ibd_sandbox.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMdqJZgYHSPM"
      },
      "source": [
        "# read csv data\n",
        "\n",
        "The pandas library will import a csv-formatted text file into a pandas DataFrame object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZhth2DFFBve"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/bryankolaczkowski/gmcdp/main/examples/ibd/data_normalized.csv\")\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSbMeAYgHPrW"
      },
      "source": [
        "# extract ASV data to numpy\n",
        "\n",
        "Numpy \"N-dimensional arrays\" (aka, \"tensors\") are a standard way to 'translate' data between different python libraries.\n",
        "\n",
        "In this case, we first extract all the columns from the DataFrame whose headers start with \"ASV_\", which indicates that the column contains abundance data (aka, the explanatory variables)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9WuzsacGNTu"
      },
      "source": [
        "asvs = [ x for x in df.columns if x.find('ASV_') == 0]\n",
        "x = df[asvs].to_numpy()\n",
        "x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIdLTYg9HVFt"
      },
      "source": [
        "# extract disease state data to numpy\n",
        "\n",
        "We'll also need the response variable, which is stored in the column called \"Group\". In this case, the response variable is a binary indicating whether the sample (row) is from an individual diagnosed with the disease, or not.\n",
        "\n",
        "In the DataFrame, disease-diagnosed rows are indicated by Group=\"CD\", and non-diagnosed rows are indicated by Group=\"Control\". We translate these labels to 0|1, using a python Dictionary (map).\n",
        "\n",
        "Response variables are also translated to a Numpy array."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnlzuttwHOni"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "c = df[['Group']]\n",
        "c = c.to_numpy().ravel()\n",
        "map = { 'CD':1, 'Control':0 }\n",
        "yl = [ map[x] for x in c]\n",
        "y = np.array(yl)\n",
        "y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuJeJyJrWP7_"
      },
      "source": [
        "# package expanatory,response variables for tensorflow\n",
        "\n",
        "Tensorflow can read Numpy arrays containing explanatory and response variables into a Dataset object that can be used to efficiently train neural networks.\n",
        "\n",
        "It's a bit difficlt to 'look at' the contents of the Dataset object, directly (although you can re-convert the Dataset to numpy arrays). The \"shape\" of the explanatory (x) and response (y) tensors includes a \"batch dimension\" (None), which will be 'filled in' by tensorflow during training, based on the specified 'batch size' of the Dataset (in this case, 10)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IaIyqGXXSe0n"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "data = tf.data.Dataset.from_tensor_slices((x,y)).batch(10)\n",
        "data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJVNzcE4Wqc5"
      },
      "source": [
        "# data visualization\n",
        "\n",
        "XX"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XKRFpAZXXje"
      },
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "cmap = ['blue', 'red']\n",
        "\n",
        "fig,ax = plt.subplots(1,1, figsize=(20,10))\n",
        "\n",
        "xax = np.arange(0, x.shape[-1], 1)\n",
        "\n",
        "for j in range(x.shape[0]):\n",
        "  yax = np.array(x[j,:])\n",
        "  ax.scatter(xax, np.flip(np.sort(yax)), color=cmap[y[j]])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}